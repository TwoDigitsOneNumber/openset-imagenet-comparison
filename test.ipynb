{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook\n",
    "This notebook is here to test things (ideas/functions/implementations/etc) out. Each section should be independent of any other section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_half_labels  = list(range(1,14))\n",
    "second_half_labels = list(range(14,27))\n",
    "second_half_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20620936, 0.04435235],\n",
       "       [0.72144327, 0.50506758],\n",
       "       [0.97917433, 0.5126422 ],\n",
       "       [0.38295848, 0.86357367],\n",
       "       [0.88862559, 0.42341483]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = np.random.rand(5,2)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(array, axis, ord=2):\n",
    "    norms = np.linalg.norm(array, axis=axis, ord=ord)\n",
    "    norms = norms.reshape((-1,1))  # reshape norms to same dim as array\n",
    "    array = np.divide(array, norms)  # normalize\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21092518, 0.8806666 , 1.10525309, 0.94467808, 0.98434524])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms = np.linalg.norm(features, axis=1, ord=2)\n",
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21092518],\n",
       "       [0.8806666 ],\n",
       "       [1.10525309],\n",
       "       [0.94467808],\n",
       "       [0.98434524]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norms = norms.reshape((-1,1))\n",
    "norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21092518, 0.21092518],\n",
       "       [0.8806666 , 0.8806666 ],\n",
       "       [1.10525309, 1.10525309],\n",
       "       [0.94467808, 0.94467808],\n",
       "       [0.98434524, 0.98434524]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# norms = norms.repeat(2, axis=1)\n",
    "# norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97764222, 0.21027526],\n",
       "       [0.81920136, 0.573506  ],\n",
       "       [0.8859277 , 0.46382336],\n",
       "       [0.40538517, 0.91414598],\n",
       "       [0.90275805, 0.43014871]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = np.divide(features, norms)\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.linalg.norm(feats, axis=1, ord=2)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones((5,3))\n",
    "labels = torch.tensor([-1,0,-1,1,2])\n",
    "kn_idx = labels >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[kn_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t[idx].scatter_(1, torch.tensor([0,1]).view(-1,1), 4, reduce='add')\n",
    "t[kn_idx] = t[kn_idx].scatter(1, labels[kn_idx].view(-1,1), 4, reduce='add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [5., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 5., 1.],\n",
       "        [1., 1., 5.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test angular margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones((3,5))\n",
    "features = torch.ones((10,3))\n",
    "labels = torch.tensor([0,0,0,1,1,1,2,2,2,3])\n",
    "\n",
    "w = F.normalize(w, dim=0)\n",
    "cos_theta = F.normalize(features, dim=1).mm(w)\n",
    "cos_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3545, 0.0045, 0.0045, 0.0045, 0.0045],\n",
       "        [0.3545, 0.0045, 0.0045, 0.0045, 0.0045],\n",
       "        [0.3545, 0.0045, 0.0045, 0.0045, 0.0045],\n",
       "        [0.0045, 0.3545, 0.0045, 0.0045, 0.0045],\n",
       "        [0.0045, 0.3545, 0.0045, 0.0045, 0.0045],\n",
       "        [0.0045, 0.3545, 0.0045, 0.0045, 0.0045],\n",
       "        [0.0045, 0.0045, 0.3545, 0.0045, 0.0045],\n",
       "        [0.0045, 0.0045, 0.3545, 0.0045, 0.0045],\n",
       "        [0.0045, 0.0045, 0.3545, 0.0045, 0.0045],\n",
       "        [0.0045, 0.0045, 0.0045, 0.3545, 0.0045]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = .35\n",
    "\n",
    "theta_m = torch.acos(cos_theta.clamp(-1+1e-5, 1-1e-5))\n",
    "theta_m.scatter_(1, labels.view(-1, 1), m, reduce='add')\n",
    "theta_m.clamp_(1e-5, math.pi)\n",
    "theta_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.2171e-02, -9.9540e-06, -9.9540e-06, -9.9540e-06, -9.9540e-06],\n",
       "        [-6.2171e-02, -9.9540e-06, -9.9540e-06, -9.9540e-06, -9.9540e-06],\n",
       "        [-6.2171e-02, -9.9540e-06, -9.9540e-06, -9.9540e-06, -9.9540e-06],\n",
       "        [-9.9540e-06, -6.2171e-02, -9.9540e-06, -9.9540e-06, -9.9540e-06],\n",
       "        [-9.9540e-06, -6.2171e-02, -9.9540e-06, -9.9540e-06, -9.9540e-06],\n",
       "        [-9.9540e-06, -6.2171e-02, -9.9540e-06, -9.9540e-06, -9.9540e-06],\n",
       "        [-9.9540e-06, -9.9540e-06, -6.2171e-02, -9.9540e-06, -9.9540e-06],\n",
       "        [-9.9540e-06, -9.9540e-06, -6.2171e-02, -9.9540e-06, -9.9540e-06],\n",
       "        [-9.9540e-06, -9.9540e-06, -6.2171e-02, -9.9540e-06, -9.9540e-06],\n",
       "        [-9.9540e-06, -9.9540e-06, -9.9540e-06, -6.2171e-02, -9.9540e-06]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_theta = torch.cos(theta_m) - cos_theta\n",
    "d_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9378, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [0.9378, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [0.9378, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 0.9378, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 0.9378, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 0.9378, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 0.9378, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 0.9378, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 0.9378, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 0.9378, 1.0000]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_theta + d_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9378, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [0.9378, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [0.9378, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 0.9378, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 0.9378, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 0.9378, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 0.9378, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 0.9378, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 0.9378, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 0.9378, 1.0000]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my version\n",
    "w = torch.ones((3,5))\n",
    "features = torch.ones((10,3))\n",
    "labels = torch.tensor([0,0,0,1,1,1,2,2,2,3])\n",
    "\n",
    "w = F.normalize(w, dim=0)\n",
    "cos_theta = F.normalize(features, dim=1).mm(w)\n",
    "\n",
    "theta_m = torch.acos(cos_theta.clamp(-1+1e-5, 1-1e-5))\n",
    "theta_m.scatter_(1, labels.view(-1, 1), m, reduce='add')\n",
    "theta_m.clamp_(1e-5, math.pi)\n",
    "cos_theta = torch.cos(theta_m)\n",
    "cos_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angular margin version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: True\n",
      "x2: False\n",
      "y: True\n",
      "z: True\n",
      "p: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones((4,2), requires_grad=True)\n",
    "y = torch.ones((4,2), requires_grad=True)\n",
    "p = torch.nn.Parameter(torch.ones(4,2))\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.ones((4,2), requires_grad=True)\n",
    "    x2 = x + y\n",
    "    x[0] = 0\n",
    "\n",
    "print(f'x: {x.requires_grad}')\n",
    "print(f'x2: {x2.requires_grad}')\n",
    "print(f'y: {y.requires_grad}')\n",
    "print(f'z: {z.requires_grad}')\n",
    "print(f'p: {p.requires_grad}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing fancy array indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([[2,3],[4,5]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = np.array([1, 0])\n",
    "arr[np.arange(arr.shape[0]), gt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[np.arange(arr.shape[0]), gt] = 5\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_idx = np.full_like(arr, False).astype(bool)\n",
    "bool_idx[np.arange(arr.shape[0]), gt] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Training/Evaluation Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores = defaultdict(lambda: defaultdict(dict))\n",
    "protocol = 2\n",
    "loss = 'entropic'\n",
    "\n",
    "file_path = f'experiments/Protocol_{protocol}/{loss}_train_arr.npz'\n",
    "data = np.load(file_path)\n",
    "for key in data.keys():  # keys are the data description, e.g., train_loss, val_conf_unk\n",
    "    training_scores[protocol][loss][key] = data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {2: defaultdict(dict,\n",
       "                         {'entropic': {'epochs': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "                                  17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "                                  34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "                                  51, 52, 53, 54, 55, 56, 57, 58, 59]),\n",
       "                           'val_conf_kn': array([0.03918746, 0.04027894, 0.04389453, 0.04733944, 0.05110316,\n",
       "                                  0.05183748, 0.05764904, 0.05810191, 0.05808123, 0.07409267,\n",
       "                                  0.07164437, 0.05348416, 0.08372325, 0.09768613, 0.09901144,\n",
       "                                  0.1096348 , 0.0947654 , 0.12071757, 0.1275288 , 0.13693486,\n",
       "                                  0.12849972, 0.13774525, 0.13266587, 0.21669345, 0.19207108,\n",
       "                                  0.18627284, 0.20956232, 0.22455019, 0.24946061, 0.21867822,\n",
       "                                  0.25108355, 0.13782002, 0.2694387 , 0.27755433, 0.27358955,\n",
       "                                  0.24645308, 0.30778408, 0.3120703 , 0.29034343, 0.21745872,\n",
       "                                  0.25123635, 0.2652662 , 0.31919697, 0.21318692, 0.3571016 ,\n",
       "                                  0.35608795, 0.3208341 , 0.29254597, 0.37159514, 0.37253252,\n",
       "                                  0.3904713 , 0.30894727, 0.31132537, 0.40545785, 0.35719568,\n",
       "                                  0.36168346, 0.32078937, 0.44144827, 0.46213648, 0.41859204],\n",
       "                                 dtype=float32),\n",
       "                           'val_conf_unk': array([0.9544702 , 0.9703251 , 0.9542483 , 0.95905143, 0.95728225,\n",
       "                                  0.956505  , 0.9319603 , 0.94674134, 0.9480223 , 0.92197514,\n",
       "                                  0.93344164, 0.9401701 , 0.9149683 , 0.89593214, 0.8845472 ,\n",
       "                                  0.89516497, 0.9058991 , 0.9022011 , 0.8956348 , 0.87805134,\n",
       "                                  0.9056196 , 0.8604582 , 0.8745926 , 0.83258533, 0.86797965,\n",
       "                                  0.8653196 , 0.8607409 , 0.8408306 , 0.8568672 , 0.8614563 ,\n",
       "                                  0.84729767, 0.7755909 , 0.8526303 , 0.8580942 , 0.84336716,\n",
       "                                  0.8824034 , 0.85885656, 0.85093355, 0.85260105, 0.8876371 ,\n",
       "                                  0.8600743 , 0.88871896, 0.87976575, 0.84968936, 0.8474566 ,\n",
       "                                  0.8489231 , 0.86546224, 0.83739245, 0.8449037 , 0.8327441 ,\n",
       "                                  0.8384302 , 0.85827005, 0.8671407 , 0.85020125, 0.8724036 ,\n",
       "                                  0.8524459 , 0.8736036 , 0.84373295, 0.8176943 , 0.8398612 ],\n",
       "                                 dtype=float32),\n",
       "                           'train_loss': array([3.4578993, 3.40524  , 3.3725972, 3.3519065, 3.3333488, 3.3165526,\n",
       "                                  3.3006456, 3.2852879, 3.2715218, 3.253845 , 3.2376878, 3.2194948,\n",
       "                                  3.2004263, 3.182767 , 3.1626709, 3.143363 , 3.1234167, 3.101658 ,\n",
       "                                  3.0831623, 3.060306 , 3.042673 , 3.0203414, 2.999848 , 2.9803898,\n",
       "                                  2.962232 , 2.9437473, 2.922837 , 2.9085343, 2.8883893, 2.873319 ,\n",
       "                                  2.8537984, 2.837975 , 2.8212986, 2.8057196, 2.7912307, 2.7765553,\n",
       "                                  2.7603886, 2.7435203, 2.7268667, 2.7169542, 2.701414 , 2.6878066,\n",
       "                                  2.6709132, 2.6614037, 2.6440668, 2.6325915, 2.62121  , 2.6086833,\n",
       "                                  2.5902033, 2.5844157, 2.5681489, 2.561865 , 2.5459046, 2.5351956,\n",
       "                                  2.5231059, 2.5151289, 2.4985616, 2.489733 , 2.4806457, 2.4687352],\n",
       "                                 dtype=float32),\n",
       "                           'val_loss': array([3.4835577, 3.3904097, 3.4221368, 3.3501608, 3.315964 , 3.3056471,\n",
       "                                  3.3940368, 3.3091247, 3.271595 , 3.2668378, 3.2326689, 3.3389428,\n",
       "                                  3.235626 , 3.2295353, 3.2762346, 3.1474984, 3.1865554, 3.1132925,\n",
       "                                  3.1093106, 3.1119027, 3.090434 , 3.1591008, 3.155747 , 3.02768  ,\n",
       "                                  3.0030255, 3.0292113, 2.9799767, 3.0079489, 2.9135454, 2.9573007,\n",
       "                                  2.9383163, 3.4312255, 2.9012303, 2.8445292, 2.9146793, 2.873068 ,\n",
       "                                  2.8164163, 2.8106408, 2.8652208, 2.9351344, 2.946094 , 2.866576 ,\n",
       "                                  2.760631 , 3.063263 , 2.765422 , 2.7641044, 2.7965317, 2.9040222,\n",
       "                                  2.787506 , 2.7935627, 2.7877414, 2.8406205, 2.8445435, 2.730556 ,\n",
       "                                  2.7418554, 2.7786782, 2.8264554, 2.6891966, 2.705664 , 2.7466002],\n",
       "                                 dtype=float32)}})})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading evaluation data/scores\n",
    "scores = defaultdict(lambda: defaultdict(dict))\n",
    "ground_truths = {}\n",
    "\n",
    "protocol = 2\n",
    "loss = 'entropic'\n",
    "alg = 'threshold'\n",
    "\n",
    "score_file = f\"experiments/Protocol_{protocol}/{loss}_{alg}_test_arr_curr.npz\"\n",
    "data = np.load(score_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gt', 'logits', 'features', 'scores']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5800, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5800, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['scores'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5800,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'line'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/user/bergh/openset-imagenet-comparison/test.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brolf.ifi.uzh.ch/home/user/bergh/openset-imagenet-comparison/test.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39;49mline(data[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m][:,\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'line'"
     ]
    }
   ],
   "source": [
    "plt.line(data['scores'][:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMNIST and Devanagari Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from openset_imagenet.dataset import OSCToyDataset, ImagenetDataset\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "# simulate cfg file\n",
    "cfg_dict = {\n",
    "    'data': {\n",
    "        'osc_toy_path': '/local/scratch/bergh/OSCToyData/',\n",
    "        'imagenet_path': '/local/scratch/datasets/ImageNet/ILSVRC2012/', # ILSVRC2012 path\n",
    "        'train_file': 'protocols/p{}_train.csv',        # relative to data directory\n",
    "        'val_file':   'protocols/p{}_val.csv'          # relative to data directory\n",
    "    },\n",
    "    'protocol': 0,\n",
    "    'batch_size': 32,\n",
    "    'workers': 4\n",
    "}\n",
    "\n",
    "cfg = dotdict(cfg_dict)\n",
    "cfg.data = dotdict(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protocols/p0_train.csv\n",
      "protocols/p0_val.csv\n"
     ]
    }
   ],
   "source": [
    "train_tr = transforms.Compose([transforms.ToTensor()])\n",
    "val_tr = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# load datasets\n",
    "\n",
    "train_file = pathlib.Path(cfg.data.train_file.format(cfg.protocol))\n",
    "val_file = pathlib.Path(cfg.data.val_file.format(cfg.protocol))\n",
    "print(train_file)\n",
    "print(val_file)\n",
    "\n",
    "train_ds = OSCToyDataset(\n",
    "    csv_file=train_file,\n",
    "    imagenet_path=cfg.data.osc_toy_path,\n",
    "    transform=train_tr\n",
    ")\n",
    "val_ds = OSCToyDataset(\n",
    "    csv_file=val_file,\n",
    "    imagenet_path=cfg.data.osc_toy_path,\n",
    "    transform=val_tr\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# create data loader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.workers,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding $s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def verify():\n",
    "#     for d in range(10):\n",
    "#         n = round_to_one(d)\n",
    "#         print(f\"d={d}, rounded={round(n,d)}, n={n}\")\n",
    "\n",
    "# verify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_one(d):\n",
    "    \"\"\"find smallest number n < 1 that rounds to 1 when rounding to d decimals.\"\"\"\n",
    "    numerator = (10**np.arange(1,d+1)).sum()*9 + 5\n",
    "    denominator = 10**(d+1)\n",
    "    return numerator/denominator\n",
    "\n",
    "def find_s(d, C, alpha):\n",
    "    \"\"\"\n",
    "    find lower strict bound on upper bound (beta) of logits s.t. the softmax for a class can still reach 1.\n",
    "\n",
    "    logit_i in [alpha, beta] forall i in {1, ..., C}\n",
    "\n",
    "    parameters\n",
    "        d(int): decimals to which round softmax\n",
    "        C(int): nr of classes, i.e., dimension of softmax\n",
    "        alpha(float): lower bound of logits.\n",
    "    \"\"\"\n",
    "    rounding_precision = round_to_one(d)\n",
    "    return np.log(rounding_precision/(1-rounding_precision)) + np.log(C-1) + alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.201646111423671\n"
     ]
    }
   ],
   "source": [
    "C = 10\n",
    "decimals = 5\n",
    "\n",
    "s = find_s(decimals, C, 0)/2\n",
    "print(s)\n",
    "logits = torch.zeros(C)\n",
    "logits[0] = s\n",
    "logits[1:] = -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.2016, -7.2016, -7.2016, -7.2016, -7.2016, -7.2016, -7.2016, -7.2016,\n",
       "        -7.2016, -7.2016])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_740034/706592448.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax = F.softmax(logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.9999e-01, 5.5556e-07, 5.5556e-07, 5.5556e-07, 5.5556e-07, 5.5556e-07,\n",
       "        5.5556e-07, 5.5556e-07, 5.5556e-07, 5.5556e-07])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = F.softmax(logits)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333e-08"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.3333e-08"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as in practice the logits are almost exclusively positive, we can use the "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For magface we need to find corresponding lambda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2266666666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lambda_lower_bound(s, l_m, u_m, l_a, u_a):\n",
    "    return ( (s* u_a**2 * l_a**2) / (u_a**2 - l_a**2) ) * ( (u_m - l_m) / (u_a - l_a) )\n",
    "\n",
    "lambda_g = lambda_lower_bound(\n",
    "    s=8,\n",
    "    l_m=.4, u_m=.8,\n",
    "    l_a=10, u_a=110\n",
    ")\n",
    "lambda_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to cosface paper\n",
    "def lower_bound_s(decimals, C):\n",
    "    p_w = round_to_one(decimals)\n",
    "    return ( (C-1) * np.log((C-1)*p_w/(1-p_w)) ) / C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol 0 (for alpha=0): beta=23.61, s=24.0 (s_cosface=21.25) => lambda_g >= 9.68 (choose 10.0)\n",
      "Protocol 1 (for alpha=0): beta=26.16, s=27.0 (s_cosface=25.94) => lambda_g >= 10.89 (choose 11.0)\n",
      "Protocol 2 (for alpha=0): beta=24.78, s=25.0 (s_cosface=23.96) => lambda_g >= 10.08 (choose 11.0)\n",
      "Protocol 3 (for alpha=0): beta=26.43, s=27.0 (s_cosface=26.25) => lambda_g >= 10.89 (choose 11.0)\n",
      "Protocol adacos 2k (for alpha=0): beta=29.02, s=30.0 (s_cosface=29.00) => lambda_g >= 12.10 (choose 13.0)\n",
      "Protocol adacos 20k (for alpha=0): beta=31.32, s=32.0 (s_cosface=31.32) => lambda_g >= 12.91 (choose 13.0)\n"
     ]
    }
   ],
   "source": [
    "# looking at parameter values i should use\n",
    "\n",
    "# key=protocol, val=nr_classs\n",
    "protocols = {\n",
    "    0: 10,\n",
    "    1: 116,\n",
    "    2: 30,\n",
    "    3: 151,\n",
    "    'adacos 2k': 2000,\n",
    "    'adacos 20k': 20000\n",
    "}\n",
    "\n",
    "decimals = 9\n",
    "alpha = 0\n",
    "\n",
    "for p, C in protocols.items():\n",
    "    beta = find_s(d=decimals, C=C, alpha=alpha)\n",
    "    s = np.ceil(beta)\n",
    "    s_cosface = lower_bound_s(decimals=decimals, C=C)\n",
    "    lambda_g = lambda_lower_bound(\n",
    "        s=s,\n",
    "        l_m=.4, u_m=.8,\n",
    "        l_a=10, u_a=110\n",
    "    )\n",
    "    print(f'Protocol {p} (for alpha={alpha}): beta={beta:.2f}, s={s} (s_cosface={s_cosface:.2f}) => lambda_g >= {lambda_g:.2f} (choose {np.ceil(lambda_g)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.load('experiments/Protocol_0/cosface_threshold_test_arr_curr.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gt', 'logits', 'features', 'scores', 'angles']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in scores.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 189.6681  ,  122.60147 ,  191.20335 , ...,  194.09506 ,\n",
       "         191.19868 ,  194.78024 ],\n",
       "       [ 166.64642 ,   30.251019,  166.52911 , ...,  166.12    ,\n",
       "         166.52957 ,  165.98073 ],\n",
       "       [ 292.21848 ,  232.69762 ,  295.4129  , ...,  301.5362  ,\n",
       "         295.40314 ,  303.01102 ],\n",
       "       ...,\n",
       "       [  64.091675, -100.51866 ,   61.923904, ...,   57.49604 ,\n",
       "          61.93067 ,   56.369328],\n",
       "       [ 168.76585 ,   -8.219255,  167.91168 , ...,  166.01784 ,\n",
       "         167.91441 ,  165.50502 ],\n",
       "       [  79.10963 ,  -91.049225,   77.058914, ...,   72.850945,\n",
       "          77.06532 ,   71.7762  ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openset-imagenet-comparison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
