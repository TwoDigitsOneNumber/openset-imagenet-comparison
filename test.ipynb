{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST and Devanagari Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from openset_imagenet.dataset import OSCToyDataset, ImagenetDataset\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "# simulate cfg file\n",
    "cfg_dict = {\n",
    "    'data': {\n",
    "        'osc_toy_path': '/local/scratch/bergh/OSCToyData/',\n",
    "        'imagenet_path': '/local/scratch/datasets/ImageNet/ILSVRC2012/', # ILSVRC2012 path\n",
    "        'train_file': 'protocols/p{}_train.csv',        # relative to data directory\n",
    "        'val_file':   'protocols/p{}_val.csv'          # relative to data directory\n",
    "    },\n",
    "    'protocol': 0,\n",
    "    'batch_size': 32,\n",
    "    'workers': 4\n",
    "}\n",
    "\n",
    "cfg = dotdict(cfg_dict)\n",
    "cfg.data = dotdict(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protocols/p0_train.csv\n",
      "protocols/p0_val.csv\n"
     ]
    }
   ],
   "source": [
    "train_tr = transforms.Compose([transforms.ToTensor()])\n",
    "val_tr = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# load datasets\n",
    "\n",
    "train_file = pathlib.Path(cfg.data.train_file.format(cfg.protocol))\n",
    "val_file = pathlib.Path(cfg.data.val_file.format(cfg.protocol))\n",
    "print(train_file)\n",
    "print(val_file)\n",
    "\n",
    "train_ds = OSCToyDataset(\n",
    "    csv_file=train_file,\n",
    "    imagenet_path=cfg.data.osc_toy_path,\n",
    "    transform=train_tr\n",
    ")\n",
    "val_ds = OSCToyDataset(\n",
    "    csv_file=val_file,\n",
    "    imagenet_path=cfg.data.osc_toy_path,\n",
    "    transform=val_tr\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# create data loader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.workers,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding $s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_one(d):\n",
    "    \"\"\"find smallest number n < 1 that rounds to 1 when rounding to d decimals.\"\"\"\n",
    "    numerator = (10**np.arange(1,d+1)).sum()*9 + 5\n",
    "    denominator = 10**(d+1)\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d=0, rounded=0.0, n=0.5\n",
      "d=1, rounded=1.0, n=0.95\n",
      "d=2, rounded=1.0, n=0.995\n",
      "d=3, rounded=1.0, n=0.9995\n",
      "d=4, rounded=1.0, n=0.99995\n",
      "d=5, rounded=1.0, n=0.999995\n",
      "d=6, rounded=1.0, n=0.9999995\n",
      "d=7, rounded=1.0, n=0.99999995\n",
      "d=8, rounded=1.0, n=0.999999995\n",
      "d=9, rounded=1.0, n=0.9999999995\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    for d in range(10):\n",
    "        n = round_to_one(d)\n",
    "        print(f\"d={d}, rounded={round(n,d)}, n={n}\")\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_s(d, C, alpha):\n",
    "    \"\"\"\n",
    "    find lower strict bound on upper bound (beta) of logits s.t. the softmax for a class can still reach 1.\n",
    "\n",
    "    logit_i in [alpha, beta] forall i in {1, ..., C}\n",
    "\n",
    "    parameters\n",
    "        d(int): decimals to which round softmax\n",
    "        C(int): nr of classes, i.e., dimension of softmax\n",
    "        alpha(float): lower bound of logits.\n",
    "    \"\"\"\n",
    "    rounding_precision = round_to_one(d)\n",
    "    return np.log(rounding_precision/(1-rounding_precision)) + np.log(C-1) + alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.60835146980369\n"
     ]
    }
   ],
   "source": [
    "C = 151\n",
    "s = find_s(5, C, 0)/2\n",
    "print(s)\n",
    "logits = torch.zeros(C)\n",
    "logits[0] = s\n",
    "logits[1:] = -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084,\n",
       "        -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084, -8.6084])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-98-b9a17febddef>:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax = F.softmax(logits)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08, 3.3333e-08,\n",
       "        3.3333e-08])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = F.softmax(logits)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333e-08"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.3333e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openset-imagenet-comparison",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
